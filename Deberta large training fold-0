{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\nrun_type = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n\nimport logging\nfrom types import SimpleNamespace\nfrom pathlib import Path\nfrom datetime import datetime\nimport math\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\nfrom transformers import TrainingArguments, Trainer\nfrom tqdm import tqdm\nfrom scipy.special import softmax\nfrom IPython.core.display import display, HTML\n\nfrom transformers import DataCollatorWithPadding\nfrom datasets import Dataset, load_metric\n\nimport wandb\n\n# From this Gist: https://gist.github.com/ihoromi4/b681a9088f348942b01711f251e5f964\ndef seed_everything(seed: int):\n    import random, os\n    import numpy as np\n    import torch\n    \n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-07-23T10:21:25.336198Z","iopub.execute_input":"2022-07-23T10:21:25.336562Z","iopub.status.idle":"2022-07-23T10:21:28.948292Z","shell.execute_reply.started":"2022-07-23T10:21:25.336467Z","shell.execute_reply":"2022-07-23T10:21:28.947309Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Load Data\n\nThe competition data includes a training CSV file which includes metadata for each essay element, and a folder containing the full essay texts.\n\nLet's start by loading these and looking at an example from the train and test set.","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/feedback-prize-effectiveness/train.csv')\ntest_df = pd.read_csv('../input/feedback-prize-effectiveness/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:28.950815Z","iopub.execute_input":"2022-07-23T10:21:28.951086Z","iopub.status.idle":"2022-07-23T10:21:29.121487Z","shell.execute_reply.started":"2022-07-23T10:21:28.951048Z","shell.execute_reply":"2022-07-23T10:21:29.120590Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_df.head(1)","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:29.122974Z","iopub.execute_input":"2022-07-23T10:21:29.123237Z","iopub.status.idle":"2022-07-23T10:21:29.144353Z","shell.execute_reply.started":"2022-07-23T10:21:29.123201Z","shell.execute_reply":"2022-07-23T10:21:29.143609Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   discourse_id      essay_id  \\\n0  0013cc385424  007ACE74B050   \n\n                                      discourse_text discourse_type  \\\n0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n\n  discourse_effectiveness  \n0                Adequate  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>discourse_id</th>\n      <th>essay_id</th>\n      <th>discourse_text</th>\n      <th>discourse_type</th>\n      <th>discourse_effectiveness</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0013cc385424</td>\n      <td>007ACE74B050</td>\n      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n      <td>Lead</td>\n      <td>Adequate</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_df.head(1)","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:29.146645Z","iopub.execute_input":"2022-07-23T10:21:29.147047Z","iopub.status.idle":"2022-07-23T10:21:29.156766Z","shell.execute_reply.started":"2022-07-23T10:21:29.147005Z","shell.execute_reply":"2022-07-23T10:21:29.155971Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   discourse_id      essay_id  \\\n0  a261b6e14276  D72CB1C11673   \n\n                                      discourse_text discourse_type  \n0  Making choices in life can be very difficult. ...           Lead  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>discourse_id</th>\n      <th>essay_id</th>\n      <th>discourse_text</th>\n      <th>discourse_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a261b6e14276</td>\n      <td>D72CB1C11673</td>\n      <td>Making choices in life can be very difficult. ...</td>\n      <td>Lead</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"len(train_df), len(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:29.158210Z","iopub.execute_input":"2022-07-23T10:21:29.158805Z","iopub.status.idle":"2022-07-23T10:21:29.167936Z","shell.execute_reply.started":"2022-07-23T10:21:29.158766Z","shell.execute_reply":"2022-07-23T10:21:29.167099Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(36765, 10)"},"metadata":{}}]},{"cell_type":"markdown","source":"The train set contains **36,756** essay elements.\n\nThe test set CSV only contains **10** elements, as the notebook needs to be submitted to run against the entire test set.","metadata":{}},{"cell_type":"markdown","source":"# Essay Texts","metadata":{}},{"cell_type":"markdown","source":"Let's see the first 200 characters of a few essay examples.","metadata":{}},{"cell_type":"code","source":"essays = train_df.essay_id.unique()\n\ntexts = []\nfor essay_id in essays[:10]:\n    texts.append(open(f'../input/feedback-prize-effectiveness/train/{essay_id}.txt').read())\n\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-07-23T10:21:29.169917Z","iopub.execute_input":"2022-07-23T10:21:29.170221Z","iopub.status.idle":"2022-07-23T10:21:29.188266Z","shell.execute_reply.started":"2022-07-23T10:21:29.170181Z","shell.execute_reply":"2022-07-23T10:21:29.187526Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Let's count the number of unique essays in the folder.","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\n\nessay_ids_in_folder = set()\nfor path in Path('../input/feedback-prize-effectiveness/train').iterdir():\n    essay_ids_in_folder.add(path.name[:-4])\nlen(essay_ids_in_folder)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-07-23T10:21:29.189261Z","iopub.execute_input":"2022-07-23T10:21:29.189477Z","iopub.status.idle":"2022-07-23T10:21:29.212103Z","shell.execute_reply.started":"2022-07-23T10:21:29.189450Z","shell.execute_reply":"2022-07-23T10:21:29.211371Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"4191"},"metadata":{}}]},{"cell_type":"markdown","source":"There are **4,191** unique essays. Not a huge dataset at all!","metadata":{}},{"cell_type":"markdown","source":"Compared with number of essays in the CSV?","metadata":{}},{"cell_type":"code","source":"train_df.essay_id.nunique()","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-07-23T10:21:29.213453Z","iopub.execute_input":"2022-07-23T10:21:29.213740Z","iopub.status.idle":"2022-07-23T10:21:29.224283Z","shell.execute_reply.started":"2022-07-23T10:21:29.213703Z","shell.execute_reply":"2022-07-23T10:21:29.223338Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"4191"},"metadata":{}}]},{"cell_type":"code","source":"essay_ids_in_folder - set(train_df.essay_id.unique()), set(train_df.essay_id.unique()) - essay_ids_in_folder","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:29.226030Z","iopub.execute_input":"2022-07-23T10:21:29.226314Z","iopub.status.idle":"2022-07-23T10:21:29.242353Z","shell.execute_reply.started":"2022-07-23T10:21:29.226276Z","shell.execute_reply":"2022-07-23T10:21:29.241473Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(set(), set())"},"metadata":{}}]},{"cell_type":"markdown","source":"So every essay in the CSV is represented in the folder. At least for the train set.","metadata":{}},{"cell_type":"markdown","source":"# Topics/Prompts\n\n[@jdoesv](https://www.kaggle.com/jdoesv) put together a really useful [notebook](https://www.kaggle.com/code/jdoesv/topics-identification), which runs [BERTopic](https://maartengr.github.io/BERTopic/index.html) across each of the training examples. This uncovers the essay prompts used for each of the training examples.\n\njdoesv determines that there are [15 essay prompts used in the dataset](https://www.kaggle.com/competitions/feedback-prize-effectiveness/discussion/327514). The topic information is useful for data analysis, and will potentially be useful in the final model, so I'm joining it with the competition dataset.","metadata":{}},{"cell_type":"code","source":"topic_pred_df = pd.read_csv('../input/feedback-topics-identification-with-bertopic/topic_model_feedback.csv')\ntopic_pred_df = topic_pred_df.drop(columns={'prob'})\ntopic_pred_df = topic_pred_df.rename(columns={'id': 'essay_id'})\n\ntopic_meta_df = pd.read_csv('../input/feedback-topics-identification-with-bertopic/topic_model_metadata.csv')\ntopic_meta_df = topic_meta_df.rename(columns={'Topic': 'topic', 'Name': 'topic_name'}).drop(columns=['Count'])\ntopic_meta_df.topic_name = topic_meta_df.topic_name.apply(lambda n: ' '.join(n.split('_')[1:]))\n\ntopic_pred_df = topic_pred_df.merge(topic_meta_df, on='topic', how='left')\n\ntrain_df = train_df.merge(topic_pred_df, on='essay_id', how='left')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-07-23T10:21:29.246516Z","iopub.execute_input":"2022-07-23T10:21:29.246740Z","iopub.status.idle":"2022-07-23T10:21:29.293239Z","shell.execute_reply.started":"2022-07-23T10:21:29.246714Z","shell.execute_reply":"2022-07-23T10:21:29.292512Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"labels = ['Adequate', 'Effective', 'Ineffective']","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:29.294460Z","iopub.execute_input":"2022-07-23T10:21:29.295041Z","iopub.status.idle":"2022-07-23T10:21:29.299722Z","shell.execute_reply.started":"2022-07-23T10:21:29.295003Z","shell.execute_reply":"2022-07-23T10:21:29.298662Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"discourse_types = train_df.discourse_type.unique()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-07-23T10:21:29.301184Z","iopub.execute_input":"2022-07-23T10:21:29.302663Z","iopub.status.idle":"2022-07-23T10:21:29.313609Z","shell.execute_reply.started":"2022-07-23T10:21:29.302632Z","shell.execute_reply":"2022-07-23T10:21:29.312860Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"It seems that you have highest probability of having your section marked `Ineffective` within the `Evidence` Discourse Type.\n\nThat makes sense as the degree of Evidence seems more objectively quantifiable.","metadata":{}},{"cell_type":"markdown","source":"## Discourse Effectiveness (label)","metadata":{}},{"cell_type":"markdown","source":"Each essay section is labelled from one of three labels: `Adequate`, `Effective`, and `Ineffective`.","metadata":{}},{"cell_type":"code","source":"labels","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:29.317245Z","iopub.execute_input":"2022-07-23T10:21:29.317452Z","iopub.status.idle":"2022-07-23T10:21:29.325078Z","shell.execute_reply.started":"2022-07-23T10:21:29.317427Z","shell.execute_reply":"2022-07-23T10:21:29.324081Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"['Adequate', 'Effective', 'Ineffective']"},"metadata":{}}]},{"cell_type":"markdown","source":"Let's explore the distribution.","metadata":{}},{"cell_type":"markdown","source":"As we can see, quite an imbalanced dataset. We may want to use some kind of weighting, or perhaps up or downsampling within the solution.","metadata":{}},{"cell_type":"markdown","source":"Let's see examples of each for each discourse type from topic: `face mars landform aliens`","metadata":{}},{"cell_type":"markdown","source":"The mean word count is 44.65 words:","metadata":{}},{"cell_type":"code","source":"train_df['word_count'] = train_df.discourse_text.apply(lambda x: len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:29.326588Z","iopub.execute_input":"2022-07-23T10:21:29.326994Z","iopub.status.idle":"2022-07-23T10:21:29.459996Z","shell.execute_reply.started":"2022-07-23T10:21:29.326949Z","shell.execute_reply":"2022-07-23T10:21:29.459249Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_df['word_count'].mean()","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:29.461249Z","iopub.execute_input":"2022-07-23T10:21:29.461602Z","iopub.status.idle":"2022-07-23T10:21:29.470880Z","shell.execute_reply.started":"2022-07-23T10:21:29.461561Z","shell.execute_reply":"2022-07-23T10:21:29.469954Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"44.65407316741466"},"metadata":{}}]},{"cell_type":"markdown","source":"The max word count is 836.","metadata":{}},{"cell_type":"code","source":"train_df['word_count'].max()","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:29.472078Z","iopub.execute_input":"2022-07-23T10:21:29.472281Z","iopub.status.idle":"2022-07-23T10:21:29.479259Z","shell.execute_reply.started":"2022-07-23T10:21:29.472256Z","shell.execute_reply":"2022-07-23T10:21:29.478409Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"836"},"metadata":{}}]},{"cell_type":"markdown","source":"Let's see the first 1000 characters:","metadata":{}},{"cell_type":"code","source":"train_df.iloc[train_df['word_count'].idxmax()].discourse_text[:1000]","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:29.481076Z","iopub.execute_input":"2022-07-23T10:21:29.481684Z","iopub.status.idle":"2022-07-23T10:21:29.490270Z","shell.execute_reply.started":"2022-07-23T10:21:29.481643Z","shell.execute_reply":"2022-07-23T10:21:29.489377Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"\"You can search the website up so that you can finished it the assignment to handle it in to your teacher if you missing anything from your others class you can finished with your others class you have with your schdule. If you stuck on the question go asked your teacher to helped you out now go to any comptuer that you wanted to be in you have to sign in thorugh your computer to logn in now you hace to wait unitl the screen show up and now go to the website that is on your paper to finished on your assignment on your homework.\\n\\nFirst now go to any comptuer that you wanted to be in you have to sign in thorugh your computer to logn in now you hace to wait unitl the screen is done. Now listen to your teachers to follow the dirction how to go in the website. If you didn't finished the assignment that you can finished it at home. When you take your worksheet home you have to bring it back if you didn't finished it your assignment it be came homework. Now the teacher said now sign off the co\""},"metadata":{}}]},{"cell_type":"markdown","source":"Let's see the word count per Discourse Type","metadata":{}},{"cell_type":"code","source":"discourse_types = train_df.discourse_type.unique()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-07-23T10:21:29.491952Z","iopub.execute_input":"2022-07-23T10:21:29.492495Z","iopub.status.idle":"2022-07-23T10:21:29.501884Z","shell.execute_reply.started":"2022-07-23T10:21:29.492455Z","shell.execute_reply":"2022-07-23T10:21:29.501054Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"So `Claim` and `Evidence` appear to have the largest word count.","metadata":{}},{"cell_type":"markdown","source":"# 2021 Data","metadata":{}},{"cell_type":"markdown","source":"In [this](https://www.kaggle.com/code/lextoumbourou/feedback-prize-inference-on-2021-dataset) notebook, I made predictions on the full 2021 set from the original Feedback competition.\n\nLet's load them here. I'll exclude any that are in the 2022 subset.","metadata":{}},{"cell_type":"code","source":"train_2021_preds_df = pd.read_csv('../input/feedback-prize-inference-on-2021-dataset/train_2021_preds.csv')\ntrain_2021_preds_df = train_2021_preds_df[train_2021_preds_df.in_2022 == False]","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:29.503121Z","iopub.execute_input":"2022-07-23T10:21:29.503731Z","iopub.status.idle":"2022-07-23T10:21:30.312664Z","shell.execute_reply.started":"2022-07-23T10:21:29.503618Z","shell.execute_reply":"2022-07-23T10:21:30.311832Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_2021_preds_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:30.314320Z","iopub.execute_input":"2022-07-23T10:21:30.314588Z","iopub.status.idle":"2022-07-23T10:21:30.333878Z","shell.execute_reply.started":"2022-07-23T10:21:30.314548Z","shell.execute_reply":"2022-07-23T10:21:30.332918Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"        essay_id  discourse_id  \\\n10  A8445CABFECE  1.622576e+12   \n11  A8445CABFECE  1.622576e+12   \n12  A8445CABFECE  1.622576e+12   \n13  A8445CABFECE  1.622576e+12   \n14  6B4F7A0165B9  1.622644e+12   \n\n                                       discourse_text        discourse_type  \\\n10  Drivers should not be able to use phones while...              Position   \n11  Drivers who used their phone while operating a...                 Claim   \n12  According to an article by the Edgar Snyder Fi...              Evidence   \n13  In conclusion, drivers should not able to work...  Concluding Statement   \n14  The ability to stay connected to people we kno...                  Lead   \n\n    in_2022  topic                 topic_name  \\\n10    False     13  driving phone phones cell   \n11    False     13  driving phone phones cell   \n12    False     13  driving phone phones cell   \n13    False     13  driving phone phones cell   \n14    False     13  driving phone phones cell   \n\n                                             essay_fn  Adequate  Effective  \\\n10  ../input/feedback-prize-2021/train/A8445CABFEC...  0.883984   0.036340   \n11  ../input/feedback-prize-2021/train/A8445CABFEC...  0.880176   0.041171   \n12  ../input/feedback-prize-2021/train/A8445CABFEC...  0.697168   0.226025   \n13  ../input/feedback-prize-2021/train/A8445CABFEC...  0.875977   0.022543   \n14  ../input/feedback-prize-2021/train/6B4F7A0165B...  0.361206   0.515234   \n\n    Ineffective discourse_effectiveness  \n10     0.079919                Adequate  \n11     0.078351                Adequate  \n12     0.076971                Adequate  \n13     0.101404                Adequate  \n14     0.123700               Effective  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>essay_id</th>\n      <th>discourse_id</th>\n      <th>discourse_text</th>\n      <th>discourse_type</th>\n      <th>in_2022</th>\n      <th>topic</th>\n      <th>topic_name</th>\n      <th>essay_fn</th>\n      <th>Adequate</th>\n      <th>Effective</th>\n      <th>Ineffective</th>\n      <th>discourse_effectiveness</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>A8445CABFECE</td>\n      <td>1.622576e+12</td>\n      <td>Drivers should not be able to use phones while...</td>\n      <td>Position</td>\n      <td>False</td>\n      <td>13</td>\n      <td>driving phone phones cell</td>\n      <td>../input/feedback-prize-2021/train/A8445CABFEC...</td>\n      <td>0.883984</td>\n      <td>0.036340</td>\n      <td>0.079919</td>\n      <td>Adequate</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>A8445CABFECE</td>\n      <td>1.622576e+12</td>\n      <td>Drivers who used their phone while operating a...</td>\n      <td>Claim</td>\n      <td>False</td>\n      <td>13</td>\n      <td>driving phone phones cell</td>\n      <td>../input/feedback-prize-2021/train/A8445CABFEC...</td>\n      <td>0.880176</td>\n      <td>0.041171</td>\n      <td>0.078351</td>\n      <td>Adequate</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>A8445CABFECE</td>\n      <td>1.622576e+12</td>\n      <td>According to an article by the Edgar Snyder Fi...</td>\n      <td>Evidence</td>\n      <td>False</td>\n      <td>13</td>\n      <td>driving phone phones cell</td>\n      <td>../input/feedback-prize-2021/train/A8445CABFEC...</td>\n      <td>0.697168</td>\n      <td>0.226025</td>\n      <td>0.076971</td>\n      <td>Adequate</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>A8445CABFECE</td>\n      <td>1.622576e+12</td>\n      <td>In conclusion, drivers should not able to work...</td>\n      <td>Concluding Statement</td>\n      <td>False</td>\n      <td>13</td>\n      <td>driving phone phones cell</td>\n      <td>../input/feedback-prize-2021/train/A8445CABFEC...</td>\n      <td>0.875977</td>\n      <td>0.022543</td>\n      <td>0.101404</td>\n      <td>Adequate</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>6B4F7A0165B9</td>\n      <td>1.622644e+12</td>\n      <td>The ability to stay connected to people we kno...</td>\n      <td>Lead</td>\n      <td>False</td>\n      <td>13</td>\n      <td>driving phone phones cell</td>\n      <td>../input/feedback-prize-2021/train/6B4F7A0165B...</td>\n      <td>0.361206</td>\n      <td>0.515234</td>\n      <td>0.123700</td>\n      <td>Effective</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"I'm going to get essays that contain the most confident predictions.\n\nThat should maintain the same distribution of discourse types.","metadata":{}},{"cell_type":"code","source":"num_essays = 2","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:30.335684Z","iopub.execute_input":"2022-07-23T10:21:30.336638Z","iopub.status.idle":"2022-07-23T10:21:30.343272Z","shell.execute_reply.started":"2022-07-23T10:21:30.336590Z","shell.execute_reply":"2022-07-23T10:21:30.342218Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_2021_preds_df['label_prob'] = train_2021_preds_df[labels].max(axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:30.344893Z","iopub.execute_input":"2022-07-23T10:21:30.345709Z","iopub.status.idle":"2022-07-23T10:21:30.359649Z","shell.execute_reply.started":"2022-07-23T10:21:30.345646Z","shell.execute_reply":"2022-07-23T10:21:30.358737Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# train_2021_preds_df = train_2021_preds_df.merge(topic_pred_df, on='essay_id', how='left')","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:30.362205Z","iopub.execute_input":"2022-07-23T10:21:30.362525Z","iopub.status.idle":"2022-07-23T10:21:30.366857Z","shell.execute_reply.started":"2022-07-23T10:21:30.362469Z","shell.execute_reply":"2022-07-23T10:21:30.366000Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"confident_essays = train_2021_preds_df[['essay_id', 'label_prob']].groupby('essay_id').mean().sort_values('label_prob', ascending=False)[:num_essays]","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:30.368445Z","iopub.execute_input":"2022-07-23T10:21:30.368983Z","iopub.status.idle":"2022-07-23T10:21:30.413421Z","shell.execute_reply.started":"2022-07-23T10:21:30.368934Z","shell.execute_reply":"2022-07-23T10:21:30.412712Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"essay_ids = set(confident_essays.index)","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:30.414788Z","iopub.execute_input":"2022-07-23T10:21:30.415226Z","iopub.status.idle":"2022-07-23T10:21:30.419174Z","shell.execute_reply.started":"2022-07-23T10:21:30.415186Z","shell.execute_reply":"2022-07-23T10:21:30.418408Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_2021_filt_df = train_2021_preds_df[train_2021_preds_df.essay_id.isin(essay_ids)].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:30.420603Z","iopub.execute_input":"2022-07-23T10:21:30.421131Z","iopub.status.idle":"2022-07-23T10:21:30.435459Z","shell.execute_reply.started":"2022-07-23T10:21:30.420995Z","shell.execute_reply":"2022-07-23T10:21:30.434641Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"train_2021_filt_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:30.438780Z","iopub.execute_input":"2022-07-23T10:21:30.439045Z","iopub.status.idle":"2022-07-23T10:21:30.448177Z","shell.execute_reply.started":"2022-07-23T10:21:30.439018Z","shell.execute_reply":"2022-07-23T10:21:30.447385Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"(2, 13)"},"metadata":{}}]},{"cell_type":"markdown","source":"Okay, let's get to training a model!","metadata":{}},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"markdown","source":"I include some additional dropout in the config as the model tends to overfit as well as label smoothing, as it seems to work slightly better in the tests I've performed.","metadata":{}},{"cell_type":"code","source":"config = SimpleNamespace()\n\nconfig.seed = 42\nconfig.model_name = 'microsoft/deberta-large'\nconfig.output_path = Path('./')\nconfig.input_path = Path('../input/feedback-prize-effectiveness')\n\nconfig.n_folds = 4\nconfig.lr = 1e-5\nconfig.weight_decay = 0.01\nconfig.epochs = 4\nconfig.batch_size = 4\nconfig.gradient_accumulation_steps = 1\nconfig.warm_up_ratio = 0.1\nconfig.max_len = 384\nconfig.hidden_dropout_prob = 0.1\nconfig.label_smoothing_factor = 0.\nconfig.eval_per_epoch = 2\n\nlogging.disable(logging.WARNING)\n\nseed_everything(config.seed)","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:23:07.060594Z","iopub.execute_input":"2022-07-23T10:23:07.061389Z","iopub.status.idle":"2022-07-23T10:23:07.073666Z","shell.execute_reply.started":"2022-07-23T10:23:07.061343Z","shell.execute_reply":"2022-07-23T10:23:07.071969Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"# WanDB","metadata":{}},{"cell_type":"code","source":"if run_type == 'Interactive':\n    print('Wandb in offline mode.')\n    os.environ['WANDB_MODE'] = 'offline'","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:23:09.140194Z","iopub.execute_input":"2022-07-23T10:23:09.140480Z","iopub.status.idle":"2022-07-23T10:23:09.146965Z","shell.execute_reply.started":"2022-07-23T10:23:09.140450Z","shell.execute_reply":"2022-07-23T10:23:09.146085Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Wandb in offline mode.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The following lines of code assumes that you have a [User Secret](https://www.kaggle.com/product-feedback/114053) setup called `wandb` with your wandb API key.","metadata":{}},{"cell_type":"code","source":"print('Authenticating with wandb.')\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwandb_creds = user_secrets.get_secret(\"wandb\")\n\n!wandb login {wandb_creds}","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:23:09.691015Z","iopub.execute_input":"2022-07-23T10:23:09.691282Z","iopub.status.idle":"2022-07-23T10:23:12.250281Z","shell.execute_reply.started":"2022-07-23T10:23:09.691253Z","shell.execute_reply":"2022-07-23T10:23:12.249131Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Authenticating with wandb.\n","output_type":"stream"}]},{"cell_type":"code","source":"wandb.config = config.__dict__","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:23:12.253475Z","iopub.execute_input":"2022-07-23T10:23:12.254181Z","iopub.status.idle":"2022-07-23T10:23:12.260059Z","shell.execute_reply.started":"2022-07-23T10:23:12.254134Z","shell.execute_reply":"2022-07-23T10:23:12.259123Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"wandb.init(project=\"feedback-prize-effectiveness\")","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:23:12.261079Z","iopub.execute_input":"2022-07-23T10:23:12.261331Z","iopub.status.idle":"2022-07-23T10:23:19.369636Z","shell.execute_reply.started":"2022-07-23T10:23:12.261304Z","shell.execute_reply":"2022-07-23T10:23:19.368755Z"},"trusted":true},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:10adacwj) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"You can sync this run to the cloud by running:<br/><code>wandb sync /kaggle/working/wandb/offline-run-20220723_102133-10adacwj<code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/offline-run-20220723_102133-10adacwj/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:10adacwj). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.16"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."},"metadata":{}},{"execution_count":43,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7f4e690cfad0>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Setup CV","metadata":{}},{"cell_type":"markdown","source":"Note that I am using `StratifiedKFold` instead of `StratifiedGroupKFold` here, as it performs better on the LB. This comes at the expense of an accurate CV score.","metadata":{}},{"cell_type":"code","source":"cv = StratifiedKFold(n_splits=config.n_folds, shuffle=True, random_state=config.seed)","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:23:19.535236Z","iopub.execute_input":"2022-07-23T10:23:19.535508Z","iopub.status.idle":"2022-07-23T10:23:19.540858Z","shell.execute_reply.started":"2022-07-23T10:23:19.535480Z","shell.execute_reply":"2022-07-23T10:23:19.539682Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"train_df['fold'] = -1\nfor fold_num, (train_idxs, test_idxs) in enumerate(cv.split(train_df.index, train_df.discourse_effectiveness, train_df.essay_id)):\n    train_df.loc[test_idxs, ['fold']] = fold_num","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:23:22.362537Z","iopub.execute_input":"2022-07-23T10:23:22.363212Z","iopub.status.idle":"2022-07-23T10:23:22.440426Z","shell.execute_reply.started":"2022-07-23T10:23:22.363159Z","shell.execute_reply":"2022-07-23T10:23:22.439628Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:23:22.951970Z","iopub.execute_input":"2022-07-23T10:23:22.952810Z","iopub.status.idle":"2022-07-23T10:23:22.967371Z","shell.execute_reply.started":"2022-07-23T10:23:22.952770Z","shell.execute_reply":"2022-07-23T10:23:22.966299Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"   discourse_id      essay_id  \\\n0  0013cc385424  007ACE74B050   \n1  9704a709b505  007ACE74B050   \n2  c22adee811b6  007ACE74B050   \n3  a10d361e54e4  007ACE74B050   \n4  db3e453ec4e2  007ACE74B050   \n\n                                      discourse_text discourse_type  \\\n0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n1  On my perspective, I think that the face is a ...       Position   \n2  I think that the face is a natural landform be...          Claim   \n3  If life was on Mars, we would know by now. The...       Evidence   \n4  People thought that the face was formed by ali...   Counterclaim   \n\n  discourse_effectiveness  topic                 topic_name  word_count  fold  \n0                Adequate     11  face mars landform aliens          67     0  \n1                Adequate     11  face mars landform aliens          41     0  \n2                Adequate     11  face mars landform aliens          21     1  \n3                Adequate     11  face mars landform aliens          72     1  \n4                Adequate     11  face mars landform aliens          18     1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>discourse_id</th>\n      <th>essay_id</th>\n      <th>discourse_text</th>\n      <th>discourse_type</th>\n      <th>discourse_effectiveness</th>\n      <th>topic</th>\n      <th>topic_name</th>\n      <th>word_count</th>\n      <th>fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0013cc385424</td>\n      <td>007ACE74B050</td>\n      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n      <td>Lead</td>\n      <td>Adequate</td>\n      <td>11</td>\n      <td>face mars landform aliens</td>\n      <td>67</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9704a709b505</td>\n      <td>007ACE74B050</td>\n      <td>On my perspective, I think that the face is a ...</td>\n      <td>Position</td>\n      <td>Adequate</td>\n      <td>11</td>\n      <td>face mars landform aliens</td>\n      <td>41</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c22adee811b6</td>\n      <td>007ACE74B050</td>\n      <td>I think that the face is a natural landform be...</td>\n      <td>Claim</td>\n      <td>Adequate</td>\n      <td>11</td>\n      <td>face mars landform aliens</td>\n      <td>21</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a10d361e54e4</td>\n      <td>007ACE74B050</td>\n      <td>If life was on Mars, we would know by now. The...</td>\n      <td>Evidence</td>\n      <td>Adequate</td>\n      <td>11</td>\n      <td>face mars landform aliens</td>\n      <td>72</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>db3e453ec4e2</td>\n      <td>007ACE74B050</td>\n      <td>People thought that the face was formed by ali...</td>\n      <td>Counterclaim</td>\n      <td>Adequate</td>\n      <td>11</td>\n      <td>face mars landform aliens</td>\n      <td>18</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df.to_csv(config.output_path / 'train_folds.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:23:23.710972Z","iopub.execute_input":"2022-07-23T10:23:23.711780Z","iopub.status.idle":"2022-07-23T10:23:24.650271Z","shell.execute_reply.started":"2022-07-23T10:23:23.711731Z","shell.execute_reply":"2022-07-23T10:23:24.649347Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"# Tokenizer","metadata":{}},{"cell_type":"code","source":"config.model_name","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:23:29.118203Z","iopub.execute_input":"2022-07-23T10:23:29.118484Z","iopub.status.idle":"2022-07-23T10:23:29.124436Z","shell.execute_reply.started":"2022-07-23T10:23:29.118452Z","shell.execute_reply":"2022-07-23T10:23:29.123566Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"'microsoft/deberta-large'"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(config.model_name, use_fast=True)\ntokenizer.model_max_length = config.max_len","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:23:30.342361Z","iopub.execute_input":"2022-07-23T10:23:30.342639Z","iopub.status.idle":"2022-07-23T10:23:36.613515Z","shell.execute_reply.started":"2022-07-23T10:23:30.342608Z","shell.execute_reply":"2022-07-23T10:23:36.612667Z"},"trusted":true},"execution_count":49,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56f5eb339734411fbe676eaef22d2522"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/475 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9630611194534a00b32567af421741e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04d89411b92143549421dd8ec593cf46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f40c715fe4e7400987765a6b891200ec"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:23:36.615208Z","iopub.execute_input":"2022-07-23T10:23:36.615531Z","iopub.status.idle":"2022-07-23T10:23:36.623587Z","shell.execute_reply.started":"2022-07-23T10:23:36.615485Z","shell.execute_reply":"2022-07-23T10:23:36.621853Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"PreTrainedTokenizerFast(name_or_path='microsoft/deberta-large', vocab_size=50265, model_max_len=384, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'sep_token': AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'cls_token': AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'mask_token': AddedToken(\"[MASK]\", rstrip=False, lstrip=True, single_word=False, normalized=True)})"},"metadata":{}}]},{"cell_type":"code","source":"def get_essay(essay_fns):\n    essay_cache = {}\n\n    output = []\n    for essay_fn in essay_fns:\n        if essay_fn not in essay_cache:\n            essay_txt = open(essay_fn).read().strip().lower()\n            essay_cache[essay_fn] = essay_txt\n        output.append(essay_cache[essay_fn])\n\n    return output","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:23:36.624748Z","iopub.execute_input":"2022-07-23T10:23:36.625105Z","iopub.status.idle":"2022-07-23T10:23:36.632538Z","shell.execute_reply.started":"2022-07-23T10:23:36.624981Z","shell.execute_reply":"2022-07-23T10:23:36.631753Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"The essay string is passed as the `text_pair` argument to the tokenisation function. I got this idea from [this](https://www.kaggle.com/code/abhishek/tez-for-feedback-v2-0) kernel. I can't tell you exactly why it helps to pass as `text_pair` instead of concatenating onto the sequence, but it seems to work a bit.","metadata":{}},{"cell_type":"code","source":"def tokenizer_func(x):\n    return tokenizer(x[\"inputs\"], get_essay(x['essay_fn']), truncation=True, max_length=config.max_len)","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:23:38.128712Z","iopub.execute_input":"2022-07-23T10:23:38.129231Z","iopub.status.idle":"2022-07-23T10:23:38.133594Z","shell.execute_reply.started":"2022-07-23T10:23:38.129188Z","shell.execute_reply":"2022-07-23T10:23:38.132762Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"Since the `discourse_type` will be potentially valuable information, I'll concatenate it to the essay elements.\n\nI'm also concatenating the topic information.\n\nLastly, converting all text to lowercase as it performs better on CV and LB.","metadata":{}},{"cell_type":"code","source":"def add_inputs(df, basepath):\n    df['essay_fn'] = basepath + '/' + df.essay_id + '.txt'\n    df['inputs'] = df.discourse_type.str.lower() +' ' + df.topic_name + tokenizer.sep_token + df.discourse_text.str.lower()\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:23:39.899337Z","iopub.execute_input":"2022-07-23T10:23:39.899999Z","iopub.status.idle":"2022-07-23T10:23:39.905037Z","shell.execute_reply.started":"2022-07-23T10:23:39.899956Z","shell.execute_reply":"2022-07-23T10:23:39.904213Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"train_df = add_inputs(train_df, str(config.input_path / 'train'))\ntrain_2021_filt_df = add_inputs(train_2021_filt_df, '../input/feedback-prize-2021/train')","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:23:40.944649Z","iopub.execute_input":"2022-07-23T10:23:40.945316Z","iopub.status.idle":"2022-07-23T10:23:41.056331Z","shell.execute_reply.started":"2022-07-23T10:23:40.945271Z","shell.execute_reply":"2022-07-23T10:23:41.055491Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"markdown","source":"For maximum experimentation flexibility, I've setup a custom head.\n\nI've included an implementation of [Multi-Sample Dropout](https://arxiv.org/abs/1905.09788) as the model is overfitting quite quickly.\n\nWhen using HuggingFace Transformers, the [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) class has a few rules you need to follow when creating custom models:\n\n* your model always return tuples or subclasses of ModelOutput.\n* your model can compute the loss if a labels argument is provided and that loss is returned as the first element of the tuple (if your model returns tuples)\n* your model can accept multiple label arguments (use the label_names in your TrainingArguments to indicate their name to the Trainer) but none of them should be named \"label\".\n\nI've also replaced the `ContextPooler` with a mean pooling layer, as it works better in the tests I've run outside of Kaggle.","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom transformers import AutoConfig, AutoModelForSequenceClassification\nfrom transformers.models.deberta_v2.modeling_deberta_v2 import ContextPooler\nfrom transformers.models.deberta_v2.modeling_deberta_v2 import StableDropout\nfrom transformers.modeling_outputs import TokenClassifierOutput\n\ndef get_dropouts(num, start_prob, increment):\n    return [StableDropout(start_prob + (increment * i)) for i in range(num)]  \n\nclass MeanPooling(nn.Module):\n    def __init__(self):\n        super(MeanPooling, self).__init__()\n        \n    def forward(self, last_hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        return mean_embeddings\n\nclass CustomModel(nn.Module):\n    def __init__(self, backbone):\n        super(CustomModel, self).__init__()\n        \n        self.model = backbone\n        self.config = self.model.config\n        self.num_labels = self.config.num_labels\n\n        # self.pooler = ContextPooler(self.config)\n        self.pooler = MeanPooling()\n        \n        self.classifier = nn.Linear(self.config.hidden_size, self.num_labels)\n    \n        self.dropouts = get_dropouts(num=5, start_prob=config.hidden_dropout_prob - 0.02, increment=0.01)\n    \n    def forward(\n        self,\n        input_ids=None,\n        attention_mask=None,\n        token_type_ids=None,\n        position_ids=None,\n        inputs_embeds=None,\n        labels=None,\n        output_attentions=None,\n        output_hidden_states=None,\n        return_dict=None\n    ):\n        outputs = self.model.deberta(\n            input_ids,\n            token_type_ids=token_type_ids,\n            attention_mask=attention_mask,\n            position_ids=position_ids,\n            inputs_embeds=inputs_embeds,\n            output_attentions=output_attentions,\n            output_hidden_states=output_hidden_states,\n            return_dict=return_dict,\n        )\n        \n        encoder_layer = outputs[0]\n        pooled_output = self.pooler(encoder_layer, attention_mask)\n                      \n        # Multi-sample dropout.\n        num_dps = float(len(self.dropouts))\n        for ii, drop in enumerate(self.dropouts):\n            if ii == 0:\n                logits = (self.classifier(drop(pooled_output)) / num_dps)\n            else:\n                logits += (self.classifier(drop(pooled_output)) / num_dps)\n\n        loss = None\n        if labels is not None:\n            loss_fn = nn.CrossEntropyLoss()\n            logits = logits.view(-1, self.num_labels)\n            loss = loss_fn(logits, labels.view(-1))\n\n        output = (logits,) + outputs[1:]\n\n        return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states, attentions=outputs.attentions)","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:23:44.276894Z","iopub.execute_input":"2022-07-23T10:23:44.277382Z","iopub.status.idle":"2022-07-23T10:23:44.320908Z","shell.execute_reply.started":"2022-07-23T10:23:44.277339Z","shell.execute_reply":"2022-07-23T10:23:44.320108Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"def get_backbone_config():\n    model_config = AutoConfig.from_pretrained(config.model_name, num_labels=3)\n    model_config.hidden_dropout_prob = config.hidden_dropout_prob\n    return model_config","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:23:45.567006Z","iopub.execute_input":"2022-07-23T10:23:45.567791Z","iopub.status.idle":"2022-07-23T10:23:45.572202Z","shell.execute_reply.started":"2022-07-23T10:23:45.567730Z","shell.execute_reply":"2022-07-23T10:23:45.571361Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    model_config = get_backbone_config()\n\n    model = AutoModelForSequenceClassification.from_pretrained(\n        config.model_name,\n        config=model_config,\n    )\n    return CustomModel(model)","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:23:46.656966Z","iopub.execute_input":"2022-07-23T10:23:46.657744Z","iopub.status.idle":"2022-07-23T10:23:46.663561Z","shell.execute_reply.started":"2022-07-23T10:23:46.657675Z","shell.execute_reply":"2022-07-23T10:23:46.662477Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"Need to save this to generate the backbone offline.","metadata":{}},{"cell_type":"code","source":"backbone_config = get_backbone_config()\nbackbone_config.save_pretrained('./backbone_config')","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:23:48.138938Z","iopub.execute_input":"2022-07-23T10:23:48.139669Z","iopub.status.idle":"2022-07-23T10:23:48.499566Z","shell.execute_reply.started":"2022-07-23T10:23:48.139610Z","shell.execute_reply":"2022-07-23T10:23:48.498748Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"model = get_model()","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:23:48.825512Z","iopub.execute_input":"2022-07-23T10:23:48.825777Z","iopub.status.idle":"2022-07-23T10:24:37.871259Z","shell.execute_reply.started":"2022-07-23T10:23:48.825746Z","shell.execute_reply":"2022-07-23T10:24:37.870321Z"},"trusted":true},"execution_count":59,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.52G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ee5dd1da6774b4783c253d18428af09"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"The loss function Cross-Entropy is identical to the competition metric when running the model output through Softmax.\n\nI'll include accuracy as an additional metric as it tends to be human interpretable.","metadata":{}},{"cell_type":"code","source":"metric = load_metric('accuracy')\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:24:48.060415Z","iopub.execute_input":"2022-07-23T10:24:48.061209Z","iopub.status.idle":"2022-07-23T10:24:48.572150Z","shell.execute_reply.started":"2022-07-23T10:24:48.061168Z","shell.execute_reply":"2022-07-23T10:24:48.571370Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# train_df = train_df.sample(n=150)\n# config.epochs = 1","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:24:48.593738Z","iopub.execute_input":"2022-07-23T10:24:48.594009Z","iopub.status.idle":"2022-07-23T10:24:48.600414Z","shell.execute_reply.started":"2022-07-23T10:24:48.593976Z","shell.execute_reply":"2022-07-23T10:24:48.599554Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"def do_fold(fold_num):\n    train_data  = train_df.query(f'fold != {fold_num}').reset_index(drop=True)\n\n    val_data  = train_df.query(f'fold == {fold_num}').reset_index(drop=True)\n    \n    # Add 2021 to train data.\n    train_data = pd.concat([train_data, train_2021_filt_df[['inputs', 'essay_fn', 'discourse_effectiveness']]]).sample(frac=1., random_state=config.seed).reset_index(drop=True)\n    print(f'Train data size: {train_data.shape}')\n\n    train_dataset = Dataset.from_pandas(train_data[['inputs', 'essay_fn', 'discourse_effectiveness']]).rename_column('discourse_effectiveness', 'label').class_encode_column(\"label\")\n    val_dataset = Dataset.from_pandas(val_data[['inputs', 'essay_fn', 'discourse_effectiveness']]).rename_column('discourse_effectiveness', 'label').class_encode_column(\"label\")\n\n    train_tok_dataset = train_dataset.map(tokenizer_func, batched=True, remove_columns=('inputs', 'essay_fn'))\n    val_tok_dataset = val_dataset.map(tokenizer_func, batched=True, remove_columns=('inputs', 'essay_fn'))\n\n    data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding='longest')\n\n    num_steps = len(train_data) / config.batch_size / config.gradient_accumulation_steps\n    eval_steps = num_steps // config.eval_per_epoch\n    print(f'Num steps: {num_steps}, eval steps: {eval_steps}')\n\n    args = TrainingArguments(\n        output_dir=config.output_path,\n        learning_rate=config.lr,\n        warmup_ratio=config.warm_up_ratio,\n        lr_scheduler_type='cosine',\n        fp16=True,\n        per_device_train_batch_size=config.batch_size,\n        per_device_eval_batch_size=config.batch_size * 2,\n        num_train_epochs=config.epochs,\n        weight_decay=config.weight_decay,\n        report_to=\"wandb\",\n\n        evaluation_strategy='steps',\n        eval_steps=eval_steps, \n        save_strategy='steps',\n        save_steps=eval_steps,\n        \n        load_best_model_at_end=True,\n        gradient_accumulation_steps=config.gradient_accumulation_steps,\n        label_smoothing_factor=config.label_smoothing_factor,\n        save_total_limit=3  # Prevents running out of disk space.\n    )\n\n    model = get_model()\n\n    trainer = Trainer(\n        model,\n        args,\n        train_dataset=train_tok_dataset,\n        eval_dataset=val_tok_dataset,\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n        compute_metrics=compute_metrics\n    )\n\n    trainer.train()\n    \n    trainer.save_model(config.output_path / f'fold_{fold_num}')\n    \n    outputs = trainer.predict(val_tok_dataset)\n\n    val_data[labels] = softmax(outputs.predictions, axis=1)\n    \n    !rm -rf {config.output_path / 'checkpoint'}*\n    \n    return val_data","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:24:48.815503Z","iopub.execute_input":"2022-07-23T10:24:48.815871Z","iopub.status.idle":"2022-07-23T10:24:48.894057Z","shell.execute_reply.started":"2022-07-23T10:24:48.815839Z","shell.execute_reply":"2022-07-23T10:24:48.893252Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"val_preds_df = pd.DataFrame()\n\nval_data = do_fold(0)\n\nval_preds_df = pd.concat([val_preds_df, val_data])","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:24:49.306212Z","iopub.execute_input":"2022-07-23T10:24:49.306752Z","iopub.status.idle":"2022-07-23T10:28:01.463937Z","shell.execute_reply.started":"2022-07-23T10:24:49.306715Z","shell.execute_reply":"2022-07-23T10:28:01.462557Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"Train data size: (27575, 11)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Casting to class labels:   0%|          | 0/28 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85cc37da99a64de995e21aa646fd705b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4cf8676f31f490383770ae83a5647be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting to class labels:   0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"914db0bde8f645c592f6a73e2185a32a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c67c61116a04fc1a445c0e217e0a828"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38068cc11c4b4a958aed04fa20650eb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"150fc56636894a8ba876d9fbc027cb2b"}},"metadata":{}},{"name":"stdout","text":"Num steps: 6893.75, eval steps: 3446.0\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='91' max='27576' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   91/27576 01:19 < 6:47:11, 1.12 it/s, Epoch 0.01/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_190/4073618954.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mval_preds_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_preds_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_preds_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_190/3810080837.py\u001b[0m in \u001b[0;36mdo_fold\u001b[0;34m(fold_num)\u001b[0m\n\u001b[1;32m     55\u001b[0m     )\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf'fold_{fold_num}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1420\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1422\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m                 if (\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_grad_scaling\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2022\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_apex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"## All Folds","metadata":{}},{"cell_type":"code","source":"for fold in range(1, config.n_folds-3):\n    val_data = do_fold(fold)\n    val_preds_df = pd.concat([val_preds_df, val_data])","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:28:01.465207Z","iopub.status.idle":"2022-07-23T10:28:01.467070Z","shell.execute_reply.started":"2022-07-23T10:28:01.466778Z","shell.execute_reply":"2022-07-23T10:28:01.466809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_preds_df.drop(columns=['inputs']).to_csv(config.output_path / 'val_preds.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:40.841027Z","iopub.status.idle":"2022-07-23T10:21:40.842040Z","shell.execute_reply.started":"2022-07-23T10:21:40.841756Z","shell.execute_reply":"2022-07-23T10:21:40.841786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_preds_df = pd.read_csv(config.output_path / 'val_preds.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:40.843567Z","iopub.status.idle":"2022-07-23T10:21:40.844506Z","shell.execute_reply.started":"2022-07-23T10:21:40.844179Z","shell.execute_reply":"2022-07-23T10:21:40.844207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_preds_df.head(1)","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:40.845981Z","iopub.status.idle":"2022-07-23T10:21:40.846724Z","shell.execute_reply.started":"2022-07-23T10:21:40.846350Z","shell.execute_reply":"2022-07-23T10:21:40.846419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CV Score","metadata":{}},{"cell_type":"code","source":"cv = log_loss(val_preds_df['discourse_effectiveness'], val_preds_df[labels])\ncv","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:40.848353Z","iopub.status.idle":"2022-07-23T10:21:40.849270Z","shell.execute_reply.started":"2022-07-23T10:21:40.848997Z","shell.execute_reply":"2022-07-23T10:21:40.849026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.log({\"cv\": cv})","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:40.850830Z","iopub.status.idle":"2022-07-23T10:21:40.851817Z","shell.execute_reply.started":"2022-07-23T10:21:40.851526Z","shell.execute_reply":"2022-07-23T10:21:40.851554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Interpretation","metadata":{}},{"cell_type":"markdown","source":"I'm going to explore some of the model's predictions. I hope to learn more about the dataset and its limitations by doing this.","metadata":{}},{"cell_type":"markdown","source":"Firstly, I'll add a column to calculate the `-log` error per example.","metadata":{}},{"cell_type":"code","source":"def compute_loss(row):\n    return -math.log(row[row.discourse_effectiveness])\n\nval_preds_df['loss'] = val_preds_df.apply(compute_loss, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:40.853464Z","iopub.status.idle":"2022-07-23T10:21:40.854344Z","shell.execute_reply.started":"2022-07-23T10:21:40.854030Z","shell.execute_reply":"2022-07-23T10:21:40.854059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And another boolean column to describe where the prediction was correct or not. ","metadata":{}},{"cell_type":"code","source":"val_preds_df['predicted'] = val_preds_df[labels].idxmax(axis=1)\nval_preds_df['is_correct'] = val_preds_df.discourse_effectiveness == val_preds_df.predicted","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:40.856272Z","iopub.status.idle":"2022-07-23T10:21:40.856801Z","shell.execute_reply.started":"2022-07-23T10:21:40.856523Z","shell.execute_reply":"2022-07-23T10:21:40.856549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Average error per class","metadata":{}},{"cell_type":"code","source":"loss_per_class = val_preds_df[['discourse_effectiveness', 'loss']].groupby('discourse_effectiveness').mean('loss')\nloss_per_class","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-07-23T10:21:40.858421Z","iopub.status.idle":"2022-07-23T10:21:40.858911Z","shell.execute_reply.started":"2022-07-23T10:21:40.858640Z","shell.execute_reply":"2022-07-23T10:21:40.858666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Whole Essays","metadata":{}},{"cell_type":"code","source":"essay1, essay2 = list(val_preds_df[val_preds_df.is_correct].sort_values('loss', ascending=True).essay_id.values[:2])","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:40.860598Z","iopub.status.idle":"2022-07-23T10:21:40.861102Z","shell.execute_reply.started":"2022-07-23T10:21:40.860841Z","shell.execute_reply":"2022-07-23T10:21:40.860866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_essay(essay1)","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:40.862663Z","iopub.status.idle":"2022-07-23T10:21:40.863185Z","shell.execute_reply.started":"2022-07-23T10:21:40.862933Z","shell.execute_reply":"2022-07-23T10:21:40.862959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_essay(essay2)","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:40.864939Z","iopub.status.idle":"2022-07-23T10:21:40.865442Z","shell.execute_reply.started":"2022-07-23T10:21:40.865170Z","shell.execute_reply":"2022-07-23T10:21:40.865196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"markdown","source":"For inference results see [Feedback Prize - DeBERTa-v3 Inference](https://www.kaggle.com/code/lextoumbourou/feedback-prize-deberta-v3-inference).\n\nI add the inference code here just for completeness.","metadata":{}},{"cell_type":"code","source":"import sys\nimport glob\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nsys.path.append('../input/feedback-topics-identification-with-bertopic/site-packages')\nfrom bertopic import BERTopic\n\ntopic_model = BERTopic.load(\"../input/feedback-topics-identification-with-bertopic/feedback_2021_topic_model\")\n\nsws = stopwords.words(\"english\") + [\"n't\",  \"'s\", \"'ve\"]\nfls = glob.glob(\"../input/feedback-prize-effectiveness/test/*.txt\")\ndocs = []\nfor fl in tqdm(fls):\n    with open(fl) as f:\n        txt = f.read()\n        word_tokens = word_tokenize(txt)\n        txt = \" \".join([w for w in word_tokens if not w.lower() in sws])\n    docs.append(txt)\n\ntopics, probs = topic_model.transform(docs)\n\npred_topics = pd.DataFrame()\ndids = list(map(lambda fl: fl.split(\"/\")[-1].split(\".\")[0], fls))\npred_topics[\"id\"] = dids\npred_topics[\"topic\"] = topics\npred_topics['prob'] = probs\npred_topics = pred_topics.drop(columns={'prob'})\npred_topics = pred_topics.rename(columns={'id': 'essay_id'})\npred_topics = pred_topics.merge(topic_meta_df, on='topic', how='left')\npred_topics","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:40.867100Z","iopub.status.idle":"2022-07-23T10:21:40.867773Z","shell.execute_reply.started":"2022-07-23T10:21:40.867481Z","shell.execute_reply":"2022-07-23T10:21:40.867508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = test_df.merge(pred_topics, on='essay_id', how='left')\ntest_df = add_inputs(test_df, str(config.input_path / 'test'))","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:40.869385Z","iopub.status.idle":"2022-07-23T10:21:40.869990Z","shell.execute_reply.started":"2022-07-23T10:21:40.869736Z","shell.execute_reply":"2022-07-23T10:21:40.869761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nall_test_data = np.zeros((config.n_folds-3, len(test_df), len(labels)))\n\nfor fold_num in range(config.n_folds-3):\n    print(f'Do fold {fold_num}')\n\n    tokenizer = AutoTokenizer.from_pretrained(f'./fold_{fold_num}')\n    tokenizer.model_max_length = config.max_len\n\n    model = get_model()\n    state_dict = torch.load(f'./fold_{fold_num}/pytorch_model.bin')\n    model.load_state_dict(state_dict)\n    \n    test_dataset = Dataset.from_pandas(test_df[['inputs', 'essay_fn']])\n    test_tok_dataset = test_dataset.map(tokenizer_func, batched=True, remove_columns=('inputs', 'essay_fn'))\n    \n    data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding='longest')\n\n    args = TrainingArguments(\n        output_dir=config.output_path,\n        learning_rate=config.lr,\n        lr_scheduler_type='cosine',\n        fp16=True,\n        evaluation_strategy='epoch',\n        per_device_train_batch_size=config.batch_size,\n        per_device_eval_batch_size=config.batch_size * 2,\n        report_to=\"none\",\n        save_strategy='no'\n    )\n    \n    trainer = Trainer(\n        model,\n        args,\n        tokenizer=tokenizer,\n        data_collator=data_collator\n    )\n    \n    outputs = trainer.predict(test_tok_dataset) \n    softmax_outputs = softmax(outputs.predictions, axis=1)\n    \n    all_test_data[fold_num] = softmax_outputs","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:40.871761Z","iopub.status.idle":"2022-07-23T10:21:40.872216Z","shell.execute_reply.started":"2022-07-23T10:21:40.871967Z","shell.execute_reply":"2022-07-23T10:21:40.871991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"preds = np.mean(all_test_data, axis=0)\noutput_df = pd.concat([test_df[['discourse_id']], pd.DataFrame(preds, columns=labels)], axis=1)\noutput_df.to_csv('submission.csv', index=False)\npd.read_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:21:40.874049Z","iopub.status.idle":"2022-07-23T10:21:40.874819Z","shell.execute_reply.started":"2022-07-23T10:21:40.874495Z","shell.execute_reply":"2022-07-23T10:21:40.874523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}